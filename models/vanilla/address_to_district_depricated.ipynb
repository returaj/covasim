{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This script is depricated because I am able to find a better dataset from incovid19 website\n",
    "### Please see another script named cases_in_district.ipynb and website: https://data.incovid19.org/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hosp_dir = '/mnt/d/books/iitm/agentBased/data/tn/covid_war_room/positive_cases/'\n",
    "pat_file = '/mnt/d/books/iitm/agentBased/data/tn/covid_war_room/patient_data/combined_csv.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_words = {\n",
    "    'unigram': ['street', 'streets', 'road', 'roads', 'nagar', 'flat', 'school', 'apartment', 'east', 'west', 'north', 'south'],\n",
    "    'default': ['s/o', 'd/o', 'w/o', 'pin', 'po', '(po)', 'part', 'opp']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NCDC positive cases dataset collected by Returaj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hdf = pd.read_excel(join(hosp_dir, 'NCDC_ICMR-report_1_To_50000_2021-10-21 15_29_42.xlsx'))\n",
    "list_df = []\n",
    "cnt = 0\n",
    "types = {\n",
    "    \"NCDC State\": \"string\",\n",
    "    \"NCDC District\": \"string\",\n",
    "    \"Surveillance Id\": \"float64\",\n",
    "    \"Test Id (ICMR)\": \"Int64\",\n",
    "    \"Patient Age\": \"Int64\",\n",
    "    \"Age In\": \"string\",\n",
    "    \"Gender\": \"string\",\n",
    "    \"Nationality\": \"string\",\n",
    "    \"Present Village Town\": \"string\",\n",
    "    \"Present Address\": \"string\",\n",
    "    \"Lab Name\": \"string\",\n",
    "    \"Resp Inf\": \"string\",\n",
    "    \"Under Med Con\": \"string\",\n",
    "    \"Travel History\": \"string\",\n",
    "    \"Date of Arrival In India\": \"string\",\n",
    "    \"Symptoms\": \"string\",\n",
    "    \"Date of Sample Tested\": \"string\",\n",
    "    \"Date of Onset of Symptoms\": \"string\",\n",
    "    \"Patient Status Code\": \"string\",\n",
    "    \"Facility where Patient Admitted\": \"string\",\n",
    "    \"Camp Code\": \"float64\",\n",
    "    \"State Code\": \"float64\",\n",
    "    \"District Code\": \"float64\",\n",
    "    \"Family Admitted Code\": \"float64\",\n",
    "    \"Outcome Code\": \"string\",\n",
    "    \"Migrated Country\": \"string\",\n",
    "    \"Date Isolation\": \"string\",\n",
    "    \"Total Contacts\": \"float64\",\n",
    "    \"Validated\": \"float64\"\n",
    "}\n",
    "for f in listdir(hosp_dir):\n",
    "    filepath = join(hosp_dir, f)\n",
    "    if isfile(filepath):\n",
    "        tmp_df = pd.read_excel(filepath, dtype=types)\n",
    "        list_df.append(tmp_df)\n",
    "        cnt += 1\n",
    "#     if cnt == 2:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf = pd.concat(list_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_nan_df = hdf[hdf['Present Address'].notna()]\n",
    "len(not_nan_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_nan_df.head(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "district_path = '/mnt/d/books/iitm/agentBased/codes/covasim/models/data/tn_districts.txt'\n",
    "district_map, district_pop = {}, {}\n",
    "with open(district_path, 'r') as fp:\n",
    "    for line in fp:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        keys = [x.strip().lower() for x in line.split(',')]\n",
    "        district_pop[keys[0]] = int(keys[-3])\n",
    "        d = keys[:-3]\n",
    "        district_map[d[0]] = d[0]\n",
    "        for i in range(1, len(d)):\n",
    "            district_map[d[i]] = d[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_word_vector_for_gen(sen, skip_words, from_pos=1):\n",
    "    if pd.isnull(sen):\n",
    "        return set()\n",
    "    sen = str(sen)\n",
    "    imp_keys = sen.strip().split(',')\n",
    "    if len(imp_keys) == 0:\n",
    "        return set()\n",
    "    if len(imp_keys) > 1:\n",
    "        imp_keys = imp_keys[from_pos:]\n",
    "    imp_keys = [re.sub(r\"[,;\\-_\\'\\\":\\.\\?\\(\\)\\/\\d]\", \" \", x).strip() for x in imp_keys]\n",
    "    unigram = []\n",
    "    for k in imp_keys:\n",
    "        w = [x.strip().lower() for x in k.split(' ') if x.strip()]\n",
    "        w = [x if x != 'st' else 'street' for x in w if (not x in skip_words['default'])]\n",
    "        w = [x for x in w if len(x) > 2]\n",
    "        unigram.extend(w)\n",
    "    bigram = []\n",
    "    for i in range(len(unigram)-1):\n",
    "        bigram.append(f'{unigram[i]}_{unigram[i+1]}')\n",
    "    keys = set(unigram + bigram)\n",
    "    keys = set([x for x in keys if (not x in skip_words['unigram'])])\n",
    "    return keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_word_vector_for_est(sen, skip_words):\n",
    "    if pd.isnull(sen):\n",
    "        return set()\n",
    "    sen = str(sen)\n",
    "    imp_keys = sen.strip().split(',')\n",
    "    if len(imp_keys) == 0:\n",
    "        return set()\n",
    "    if len(imp_keys) > 1:\n",
    "        imp_keys = imp_keys[-1:]\n",
    "    imp_keys = [re.sub(r\"[,;\\-_\\'\\\":\\.\\?\\/\\d]\", \" \", x).strip() for x in imp_keys]\n",
    "    unigram = []\n",
    "    for k in imp_keys:\n",
    "        w = [x.strip().lower() for x in k.split(' ') if x.strip()]\n",
    "        w = [x if x != 'st' else 'street' for x in w if (not x in skip_words['default'])]\n",
    "        w = [x for x in w if len(x) > 2]\n",
    "        unigram.extend(w)\n",
    "    unigram = unigram[-3:]\n",
    "    bigram = []\n",
    "    for i in range(len(unigram)-1):\n",
    "        bigram.append(f'{unigram[i]}_{unigram[i+1]}')\n",
    "    keys = set(unigram + bigram)\n",
    "    keys = set([x for x in keys if (not x in skip_words['unigram'])])\n",
    "    return keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_possible_district(address, district_map, skip_words, from_pos):\n",
    "    words = create_word_vector_for_gen(address, skip_words, from_pos=from_pos)\n",
    "    possible_districts = [district_map[x] for x in district_map.keys() if x in words]\n",
    "    return (words, possible_districts)\n",
    "\n",
    "def population_based(possible_districts, district_pop):\n",
    "    dist = \"\"\n",
    "    for d in possible_districts:\n",
    "        if (dist == \"\") or (district_pop[dist] < district_pop[d]):\n",
    "            dist = d\n",
    "    return dist\n",
    "\n",
    "def get_district(address_districts, facility_districts, present_districts, district_pop):\n",
    "    dist = []\n",
    "    for ad in address_districts:\n",
    "        for pd in present_districts:\n",
    "            if pd == ad:\n",
    "                dist.append(ad)\n",
    "        for fd in facility_districts:\n",
    "            if fd in dist:\n",
    "                return fd\n",
    "            if fd == ad:\n",
    "                dist.append(fd)\n",
    "    if len(dist) > 0:\n",
    "        return dist[0]\n",
    "    if len(address_districts) > 0:\n",
    "        return population_based(address_districts, district_pop)\n",
    "    elif len(present_districts) > 0:\n",
    "        return population_based(present_districts, district_pop)\n",
    "    else:\n",
    "        return population_based(facility_districts, district_pop)\n",
    "\n",
    "\n",
    "def create_word_frequency(df, district_map, district_pop, skip_words):\n",
    "    word_freq, dist_cnt = {}, defaultdict(int)\n",
    "    known_district, unknown_district = [], []\n",
    "    for idx, row in df.iterrows():\n",
    "        address_words, address_districts = get_possible_district(row['Present Address'], district_map, skip_words, from_pos=-1)\n",
    "\n",
    "        facility_words, facility_districts = get_possible_district(row['Facility where Patient Admitted'], district_map, skip_words, from_pos=0)\n",
    "\n",
    "        present_words, present_districts = get_possible_district(row['Present Village Town'], district_map, skip_words, from_pos=0)\n",
    "\n",
    "        if not (address_districts or facility_districts or present_districts):\n",
    "            unknown_district.append(idx)\n",
    "            continue\n",
    "\n",
    "        dist = get_district(address_districts, facility_districts, present_districts, district_pop)\n",
    "        \n",
    "        words = address_words.union(present_words)\n",
    "        for w in words:\n",
    "            if w not in word_freq:\n",
    "                word_freq[w] = defaultdict(int)\n",
    "            word_freq[w][dist] += 1\n",
    "        dist_cnt[dist] += 1\n",
    "        known_district.append((idx, dist))\n",
    "\n",
    "#     for k, v in word_freq.items():\n",
    "#         for d in v.keys():\n",
    "#             v[d] /= dist_cnt[d]\n",
    "\n",
    "#     total_cnt = sum(dist_cnt.values())\n",
    "#     for k in dist_cnt.keys():\n",
    "#         dist_cnt[k] /= total_cnt\n",
    "\n",
    "    return (word_freq, dist_cnt, known_district, unknown_district)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_district(df, unknown, word_prob, dist_prob, skip_words, other=False):\n",
    "    estimated, new_unknown = [], []\n",
    "    max_value = np.log(0.25*1e-5)\n",
    "    for idx in unknown:\n",
    "        if other:\n",
    "            words = create_word_vector_for_est(df.loc[idx]['Address'], skip_words)\n",
    "        else:\n",
    "            address_words = create_word_vector_for_est(df.loc[idx]['Present Address'], skip_words)\n",
    "            present_words = create_word_vector_for_est(df.loc[idx]['Present Village Town'], skip_words)\n",
    "            words = address_words.union(present_words)\n",
    "        dist, logit = \"\", -np.inf\n",
    "        for d in dist_prob.keys():\n",
    "            logp = 0\n",
    "            for w in words:\n",
    "                if (w not in word_prob) or (word_prob[w][d] == 0):\n",
    "                    logp += max_value\n",
    "                else:\n",
    "                    logp += np.log(word_prob[w][d])\n",
    "            if logp == max_value*len(words):\n",
    "                continue\n",
    "            logp += np.log(dist_prob[d]) # not using this because district counts are highly imbalanced\n",
    "            if logp > logit:\n",
    "                dist, logit = d, logp\n",
    "        if dist == \"\":\n",
    "            new_unknown.append(idx)\n",
    "        else:\n",
    "            estimated.append((idx, dist))\n",
    "    return (estimated, new_unknown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_column_district(df, known, estimated):\n",
    "    k, total_k = 0, len(known)\n",
    "    e, total_e = 0, len(estimated)\n",
    "    pos, total = 0, len(df)\n",
    "    districts = []\n",
    "    while k < total_k or e < total_e or pos < total:\n",
    "        if k < total_k and known[k][0] == pos:\n",
    "            districts.append(known[k][1])\n",
    "            k += 1\n",
    "        elif e < total_e and estimated[e][0] == pos:\n",
    "            districts.append(estimated[e][1])\n",
    "            e += 1\n",
    "        else:\n",
    "            districts.append(np.nan)\n",
    "        pos += 1\n",
    "    return districts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_words(word_prob):\n",
    "    remove = []\n",
    "    for k, v in word_prob.items():\n",
    "        max_v = 0\n",
    "        for d, p in v.items():\n",
    "            max_v = max(max_v, p)\n",
    "        # about 99.8% of the data is within 32 size\n",
    "        if ((max_v < 1e-3 and len(k) <= 3) or (max_v < 1e-5) or (len(k) > 32)):\n",
    "            remove.append(k)\n",
    "    for k in remove:\n",
    "        word_prob.pop(k)\n",
    "        \n",
    "    return word_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq, dist_cnt, known_district, unknown_district = create_word_frequency(not_nan_df, district_map, district_pop, skip_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.31598924196211614\n",
    "len(known_district) / len(not_nan_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# known_district[871:875]\n",
    "# hdf.loc[[7355,7364,7370,7382]][['Present Address', 'Present Village Town', 'Facility where Patient Admitted']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run this block to see how district known dataset is imbalanced.\n",
    "\n",
    "# kv = defaultdict(int)\n",
    "# for idx, d in known_district:\n",
    "#     kv[d] += 1\n",
    "# print(kv)\n",
    "\n",
    "# print(dist_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# est, un = estimate_district(hdf, unknown_district, word_freq, dist_cnt, skip_words)\n",
    "\n",
    "# districts = get_new_column_district(hdf, known_district, est)\n",
    "\n",
    "# hdf['estimated_district'] = districts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(est) + len(known_district)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hdf[hdf['estimated_district'] == 'tuticorin'][['NCDC District', 'Present Address', 'Present Village Town', 'Facility where Patient Admitted']].head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Positive cases dataset shared by Sid\n",
    "## Please be careful when you run this block of codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wc {pat_file}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = {\n",
    "    \"Survellence ID\": 'float64',\n",
    "    \"Test ID\": 'Int64',\n",
    "    \"Lab Patient ID\": \"string\",\n",
    "    \"Age\": 'Int64',\n",
    "    \"Gender\": \"string\",\n",
    "    \"Address\": \"string\",\n",
    "    \"Date of Confirmation\": \"string\",\n",
    "    \"Nationality\": \"string\",\n",
    "    \"Total Contact\": 'float64',\n",
    "    \"Trace Contact\": 'float64',\n",
    "    \"Outcome Status\": \"string\",\n",
    "    \"Name\": \"string\",\n",
    "    \"Contact Number\": 'Int64',\n",
    "}\n",
    "pdf = pd.read_csv(pat_file, sep=',', dtype=types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_nan_pdf = pdf[pdf['Address'].notna()]\n",
    "len(not_nan_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_known_unknown_dist(df, district_map, district_pop, word_freq, dist_cnt, skip_words):\n",
    "    known_district, unknown_district = [], []\n",
    "    for idx, row in df.iterrows():\n",
    "        words, address_districts = get_possible_district(row['Address'], district_map, skip_words, from_pos=-1)\n",
    "        if not address_districts:\n",
    "            unknown_district.append(idx)\n",
    "            continue\n",
    "        dist = population_based(address_districts, district_pop)\n",
    "        for w in words:\n",
    "            if w not in word_freq:\n",
    "                word_freq[w] = defaultdict(int)\n",
    "            word_freq[w][dist] += 1\n",
    "        dist_cnt[dist] += 1\n",
    "        known_district.append((idx, dist))\n",
    "\n",
    "    for k, v in word_freq.items():\n",
    "        for d in v.keys():\n",
    "            v[d] /= dist_cnt[d]\n",
    "\n",
    "    total_cnt = sum(dist_cnt.values())\n",
    "    for k in dist_cnt.keys():\n",
    "        dist_cnt[k] /= total_cnt\n",
    "\n",
    "    return (word_freq, dist_cnt, known_district, unknown_district)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_prob, dist_prob, known, unknown = get_known_unknown_dist(not_nan_pdf, district_map, district_pop, word_freq, dist_cnt, skip_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.20802225297704172\n",
    "len(known) / (len(known) + len(unknown))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kv = defaultdict(int)\n",
    "# for idx, d in known:\n",
    "#     kv[d] += 1\n",
    "# print(kv)\n",
    "\n",
    "# dist_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len_cnt = defaultdict(int)\n",
    "for k, v in word_prob.items():\n",
    "    len_cnt[len(k)] += 1\n",
    "\n",
    "total, cum = len(word_prob), 0\n",
    "for i in range(70):\n",
    "    if len_cnt[i] == 0:\n",
    "        continue\n",
    "    cum += len_cnt[i]\n",
    "    print(f'{i}: {len_cnt[i]}, {cum / total}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "word_prob_copy = deepcopy(word_prob)\n",
    "f_word_prob = filter_words(word_prob_copy)\n",
    "\n",
    "# ((max_v < 1e-3 and len(k) <= 3) or (max_v < 1e-5) or (len(k) > 32)):\n",
    "# filtered: 400186 not_filtered: 489125\n",
    "\n",
    "# ((max_v < 1e-3 and len(k) <= 3) or (max_v < 1e-4) or (len(k) > 32)):\n",
    "# filtered: 148824 not_filtered: 489125\n",
    "print(f'filtered: {len(f_word_prob)} not_filtered: {len(word_prob)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "est, un = estimate_district(pdf, unknown, f_word_prob, dist_prob, skip_words, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2504669\n",
    "# len(est) + len(known)\n",
    "\n",
    "# 271409\n",
    "# len(un)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "districts = get_new_column_district(pdf, known, est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf['estimated_district'] = districts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dstr = '24-05-2021 09:36:59'\n",
    "datetime.strptime(dstr, '%d-%m-%Y %H:%M:%S').strftime('%d-%m-%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_date(date_str, date_frmt):\n",
    "    try:\n",
    "        d = datetime.strptime(date_str, date_frmt).strftime('%Y-%m-%d')\n",
    "        return d\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def get_time(df):\n",
    "    dates = []\n",
    "    for idx, row in df.iterrows():\n",
    "        d = convert_to_date(row['Date of Confirmation'], '%d-%m-%Y %H:%M')\n",
    "        if d is None:\n",
    "            d = convert_to_date(row['Date of Confirmation'], '%d-%m-%Y %H:%M:%S')\n",
    "        if d is None:\n",
    "            d = np.nan\n",
    "        dates.append(d)\n",
    "    return dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dates = get_time(pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pdf['dates'] = dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run when needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = pdf.groupby(['Outcome Status', 'estimated_district'])['Date of Confirmation'].agg([\"size\", \"max\"]).rename(columns={'size':'count', 'max':'to_date'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "status[status['Outcome Status'] == 'Death']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chengalpattu, 263, 2555\n",
    "# Kancheepuram, 268, 1270\n",
    "# Kanyakumari, 541, 1063\n",
    "# Thiruvallur, 1059, 1866\n",
    "# Tirupathur, 50, 627\n",
    "# tiruvannamalai, 124, 673\n",
    "# trichirappalli, 104, 1104"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## district and age based outcome count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf['age_bin'] = pdf.apply(lambda r: 15 if r['Age']>=75 else int(r['Age']/5), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf.head(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save pdf dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_file = '/mnt/d/books/iitm/agentBased/data/tn/covid_war_room/patient_data/refactored.csv'\n",
    "pdf.to_csv(pdf_file, sep=',', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All main computation happens from here. Please run above if you want to verify else proceed from here !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read pdf dataframe\n",
    "pdf_file = '/mnt/d/books/iitm/agentBased/data/tn/covid_war_room/patient_data/refactored.csv'\n",
    "types = {\n",
    "    \"Survellence ID\": 'float64',\n",
    "    \"Test ID\": 'Int64',\n",
    "    \"Lab Patient ID\": \"string\",\n",
    "    \"Age\": 'Int64',\n",
    "    \"Gender\": \"string\",\n",
    "    \"Address\": \"string\",\n",
    "    \"Date of Confirmation\": \"string\",\n",
    "    \"Nationality\": \"string\",\n",
    "    \"Total Contact\": 'float64',\n",
    "    \"Trace Contact\": 'float64',\n",
    "    \"Outcome Status\": \"string\",\n",
    "    \"Name\": \"string\",\n",
    "    \"Contact Number\": 'Int64',\n",
    "    \"estimated_district\": \"string\",\n",
    "    \"age_bin\": \"Int64\",\n",
    "    \"dates\": \"string\"\n",
    "}\n",
    "pdf = pd.read_csv(pdf_file, sep=',', dtype=types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf.head(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# not_na = pdf[pdf['estimated_district'].notna()]\n",
    "from_aug = pdf[(pdf['dates'] >= '2021-08-01') & pdf['estimated_district'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_count_by_date = from_aug.groupby(['estimated_district', 'Outcome Status', 'age_bin', 'dates'])['Test ID'].agg(['size']).rename(columns={'size':'count'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_count_by_date.head(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using cnt_district we know that start_time = '2021-08-01' to end_time = '2021-10-08'\n",
    "cnt_district = {}\n",
    "districts = age_count_by_date.estimated_district.unique()\n",
    "for d in districts:\n",
    "    tmp = age_count_by_date[(age_count_by_date['estimated_district']==d)].dates.unique()\n",
    "    cnt_district[d] = (min(tmp), max(tmp), len(tmp))\n",
    "cnt_district"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_cnt = from_aug.groupby(['estimated_district', 'Outcome Status', 'age_bin'])['Test ID'].agg(['size']).rename(columns={'size':'count'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_cnt['expected_infection'] = exp_cnt['count'].apply(lambda c: c/69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_cnt.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_cnt['Outcome Status'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_cnt[(exp_cnt['estimated_district'] == 'chennai') & (exp_cnt['Outcome Status'] == 'Discharge')]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
